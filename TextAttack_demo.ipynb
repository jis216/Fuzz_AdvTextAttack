{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS239 project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install TextAttack and Tensorflow"
      ],
      "metadata": {
        "id": "9VzlYHnvo_zE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tfedKhpNBozM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4c2a99ab-16dd-403e-d6b3-814fd1258798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textattack in /usr/local/lib/python3.7/dist-packages (0.3.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from textattack) (3.2.5)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (from textattack) (1.2.1)\n",
            "Requirement already satisfied: lemminflect in /usr/local/lib/python3.7/dist-packages (from textattack) (0.2.2)\n",
            "Requirement already satisfied: bert-score>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from textattack) (0.3.11)\n",
            "Requirement already satisfied: transformers>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from textattack) (4.16.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from textattack) (8.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from textattack) (3.4.2)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from textattack) (4.49.0)\n",
            "Requirement already satisfied: torch!=1.8,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from textattack) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy>=1.19.2 in /usr/local/lib/python3.7/dist-packages (from textattack) (1.19.5)\n",
            "Requirement already satisfied: word2number in /usr/local/lib/python3.7/dist-packages (from textattack) (1.1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from textattack) (1.7.1)\n",
            "Requirement already satisfied: flair in /usr/local/lib/python3.7/dist-packages (from textattack) (0.10)\n",
            "Requirement already satisfied: language-tool-python in /usr/local/lib/python3.7/dist-packages (from textattack) (2.7.0)\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.7/dist-packages (from textattack) (0.5.10)\n",
            "Requirement already satisfied: lru-dict in /usr/local/lib/python3.7/dist-packages (from textattack) (1.1.7)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from textattack) (1.4.1)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from textattack) (0.5.3)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.7/dist-packages (from textattack) (3.1.10)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from textattack) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from bert-score>=0.3.5->textattack) (3.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bert-score>=0.3.5->textattack) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from bert-score>=0.3.5->textattack) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->bert-score>=0.3.5->textattack) (3.0.7)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->textattack) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->textattack) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->textattack) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch!=1.8,>=1.7.0->textattack) (3.10.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.3.0->textattack) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.3.0->textattack) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.3.0->textattack) (0.11.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=3.3.0->textattack) (3.10.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=3.3.0->textattack) (0.0.47)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.3.0->textattack) (0.4.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets->textattack) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets->textattack) (6.0.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets->textattack) (0.70.12.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets->textattack) (0.3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score>=0.3.5->textattack) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score>=0.3.5->textattack) (2.0.11)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score>=0.3.5->textattack) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bert-score>=0.3.5->textattack) (1.24.3)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from flair->textattack) (6.0.3)\n",
            "Requirement already satisfied: sentencepiece==0.1.95 in /usr/local/lib/python3.7/dist-packages (from flair->textattack) (0.1.95)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair->textattack) (1.0.2)\n",
            "Requirement already satisfied: konoha<5.0.0,>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from flair->textattack) (4.6.5)\n",
            "Requirement already satisfied: gdown==3.12.2 in /usr/local/lib/python3.7/dist-packages (from flair->textattack) (3.12.2)\n",
            "Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.7/dist-packages (from flair->textattack) (1.5.11)\n",
            "Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.7/dist-packages (from flair->textattack) (1.2.13)\n",
            "Requirement already satisfied: conllu>=4.0 in /usr/local/lib/python3.7/dist-packages (from flair->textattack) (4.4.1)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair->textattack) (3.6.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair->textattack) (0.8.9)\n",
            "Requirement already satisfied: bpemb>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from flair->textattack) (0.3.3)\n",
            "Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from flair->textattack) (1.7.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair->textattack) (4.2.6)\n",
            "Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.7/dist-packages (from flair->textattack) (0.3)\n",
            "Requirement already satisfied: janome in /usr/local/lib/python3.7/dist-packages (from flair->textattack) (0.4.1)\n",
            "Requirement already satisfied: wikipedia-api in /usr/local/lib/python3.7/dist-packages (from flair->textattack) (0.5.4)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (from flair->textattack) (1.0.9)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair->textattack) (1.13.3)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair->textattack) (5.2.1)\n",
            "Requirement already satisfied: overrides<4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from konoha<5.0.0,>=4.0.0->flair->textattack) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=3.3.0->textattack) (3.7.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.3.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair->textattack) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair->textattack) (3.1.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair->textattack) (0.2.5)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words->textattack) (0.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.3.0->textattack) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install textattack"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install tensorflow_text"
      ],
      "metadata": {
        "id": "3LDzkMnhEFHK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "598bdd2b-a285-4d0e-8cbc-3a2eafb2b2f3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_text in /usr/local/lib/python3.7/dist-packages (2.8.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.9,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.43.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (0.23.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.13.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.21.5)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (3.17.3)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (13.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (3.10.0.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (2.27.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (2.0.11)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "ZOdimMshVfo-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "cf4a468f-9365-46f3-b4fd-cb3baacf9f61"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.1.95)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.21.5)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.2.5)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.16.2)\n",
            "Requirement already satisfied: tokenizers>=0.10.3 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.49.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.11.1+cu111)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence_transformers) (3.10.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2.27.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.0.47)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (4.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2.0.11)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and List all Attacks integrated into TextAttack"
      ],
      "metadata": {
        "id": "aV0hTzafoxcy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### All the integrated Attacks"
      ],
      "metadata": {
        "id": "U_YOXli8jMsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!textattack list attack-recipes"
      ],
      "metadata": {
        "id": "VAffDNiaB_7P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3eb34e95-ffed-4e1f-ddd6-a89058f1b59a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94ma2t\u001b[0m (textattack.attack_recipes.A2TYoo2021)\n",
            "\u001b[94malzantot\u001b[0m (textattack.attack_recipes.GeneticAlgorithmAlzantot2018)\n",
            "\u001b[94mbae\u001b[0m (textattack.attack_recipes.BAEGarg2019)\n",
            "\u001b[94mbert-attack\u001b[0m (textattack.attack_recipes.BERTAttackLi2020)\n",
            "\u001b[94mchecklist\u001b[0m (textattack.attack_recipes.CheckList2020)\n",
            "\u001b[94mclare\u001b[0m (textattack.attack_recipes.CLARE2020)\n",
            "\u001b[94mdeepwordbug\u001b[0m (textattack.attack_recipes.DeepWordBugGao2018)\n",
            "\u001b[94mfaster-alzantot\u001b[0m (textattack.attack_recipes.FasterGeneticAlgorithmJia2019)\n",
            "\u001b[94mhotflip\u001b[0m (textattack.attack_recipes.HotFlipEbrahimi2017)\n",
            "\u001b[94miga\u001b[0m (textattack.attack_recipes.IGAWang2019)\n",
            "\u001b[94minput-reduction\u001b[0m (textattack.attack_recipes.InputReductionFeng2018)\n",
            "\u001b[94mkuleshov\u001b[0m (textattack.attack_recipes.Kuleshov2017)\n",
            "\u001b[94mmorpheus\u001b[0m (textattack.attack_recipes.MorpheusTan2020)\n",
            "\u001b[94mpruthi\u001b[0m (textattack.attack_recipes.Pruthi2019)\n",
            "\u001b[94mpso\u001b[0m (textattack.attack_recipes.PSOZang2020)\n",
            "\u001b[94mpwws\u001b[0m (textattack.attack_recipes.PWWSRen2019)\n",
            "\u001b[94mseq2sick\u001b[0m (textattack.attack_recipes.Seq2SickCheng2018BlackBox)\n",
            "\u001b[94mtextbugger\u001b[0m (textattack.attack_recipes.TextBuggerLi2018)\n",
            "\u001b[94mtextfooler\u001b[0m (textattack.attack_recipes.TextFoolerJin2019)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Results of Existing Attacks"
      ],
      "metadata": {
        "id": "8HqUYRywoe5k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We make each attack generate 10 examples. The commands all follow this structure below: \n",
        "\n",
        "`textattack attack --model <model to attack> --recipe <attack method> --num-examples <number of seeds/attacks>`.\n",
        "\n",
        "Just by looking at these examples, it is easy to tell that most of them are not grammatically correct and may have already change the original meaning of the sentence. These attacks are also listed below in the order of the fastest to the slowest speed. We can see that for the attack using genetic algorithm as optimization method, it can take hours to generate one single adversarial example.\n",
        "\n",
        "These observations lead us to the goal of our project: we want to build a attack method with speed on par with `a2t` without trading-off generation quality and attack success rate too much. (It is obvious that compared to other methods, attack of `a2t` is highly likely to fail)"
      ],
      "metadata": {
        "id": "w6FttK78omLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!textattack attack --model bert-base-uncased-sst2 --recipe a2t --num-examples 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9Mo3_rgUGG1o",
        "outputId": "23e6f554-942e-47f7-d65d-c1c9dd5d8532"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mglue\u001b[0m, subset \u001b[94msst2\u001b[0m, split \u001b[94mvalidation\u001b[0m.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading pre-trained model from HuggingFace model repository: \u001b[94mtextattack/bert-base-uncased-SST-2\u001b[0m\n",
            "Downloading: 100% 523/523 [00:00<00:00, 328kB/s]\n",
            "Downloading: 100% 3.93k/3.93k [00:00<00:00, 2.36MB/s]\n",
            "Downloading: 100% 539/539 [00:00<00:00, 286kB/s]\n",
            "Downloading: 100% 122/122 [00:00<00:00, 88.5kB/s]\n",
            "Downloading: 100% 229/229 [00:00<00:00, 168kB/s]\n",
            "Downloading: 100% 265M/265M [00:11<00:00, 23.1MB/s]\n",
            "Downloading: 100% 53.0/53.0 [00:00<00:00, 38.7kB/s]\n",
            "Downloading: 100% 112/112 [00:00<00:00, 75.1kB/s]\n",
            "Downloading: 100% 466k/466k [00:00<00:00, 4.57MB/s]\n",
            "Downloading: 100% 489/489 [00:00<00:00, 323kB/s]\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 2.86MB/s]\n",
            "Downloading: 100% 190/190 [00:00<00:00, 132kB/s]\n",
            "\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "Attack(\n",
            "  (search_method): GreedyWordSwapWIR(\n",
            "    (wir_method):  gradient\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  WordSwapEmbedding(\n",
            "    (max_candidates):  20\n",
            "    (embedding):  WordEmbedding\n",
            "  )\n",
            "  (constraints): \n",
            "    (0): PartOfSpeech(\n",
            "        (tagger_type):  nltk\n",
            "        (tagset):  universal\n",
            "        (allow_verb_noun_swap):  False\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): BERT(\n",
            "        (metric):  cosine\n",
            "        (threshold):  0.9\n",
            "        (window_size):  inf\n",
            "        (skip_text_shorter_than_window):  False\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (2): WordEmbeddingDistance(\n",
            "        (embedding):  WordEmbedding\n",
            "        (min_cos_sim):  0.8\n",
            "        (cased):  False\n",
            "        (include_unknown_words):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (3): RepeatModification\n",
            "    (4): StopwordModification\n",
            "    (5): InputColumnModification(\n",
            "        (matching_column_labels):  ['premise', 'hypothesis']\n",
            "        (columns_to_ignore):  {'premise'}\n",
            "      )\n",
            "    (6): MaxModificationRate(\n",
            "        (max_rate):  0.1\n",
            "        (min_threshold):  4\n",
            "      )\n",
            "  (is_black_box):  False\n",
            ") \n",
            "\n",
            "  0% 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            " 10% 1/10 [00:29<04:23, 29.25s/it]--------------------------------------------- Result 1 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "it 's a charming and often affecting journey . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:  20% 2/10 [00:48<03:13, 24.13s/it]--------------------------------------------- Result 2 ---------------------------------------------\n",
            "\u001b[91mNegative (99%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "unflinchingly bleak and desperate \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 2 / 0 / 2:  30% 3/10 [01:26<03:20, 28.67s/it]--------------------------------------------- Result 3 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (97%)\u001b[0m\n",
            "\n",
            "\u001b[92mallows\u001b[0m us to \u001b[92mhope\u001b[0m that nolan is \u001b[92mpoised\u001b[0m to embark a major career as a commercial \u001b[92myet\u001b[0m inventive filmmaker . \n",
            "\n",
            "\u001b[91mauthorizes\u001b[0m us to \u001b[91mhopes\u001b[0m that nolan is \u001b[91mprepped\u001b[0m to embark a major career as a commercial \u001b[91mhowever\u001b[0m inventive filmmaker . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 1 / 2 / 0 / 3:  40% 4/10 [01:51<02:47, 27.84s/it]--------------------------------------------- Result 4 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (62%)\u001b[0m\n",
            "\n",
            "the acting , costumes , music , cinematography and sound are all \u001b[92mastounding\u001b[0m given the \u001b[92mproduction\u001b[0m 's austere locales . \n",
            "\n",
            "the acting , costumes , music , cinematography and sound are all \u001b[91mstaggering\u001b[0m given the \u001b[91mproductivity\u001b[0m 's austere locales . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 2 / 2 / 0 / 4:  50% 5/10 [02:08<02:08, 25.71s/it]--------------------------------------------- Result 5 ---------------------------------------------\n",
            "\u001b[91mNegative (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "it 's slow -- very , very slow . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 2 / 3 / 0 / 5:  60% 6/10 [02:45<01:50, 27.65s/it]--------------------------------------------- Result 6 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "although laced with humor and a few fanciful touches , the film is a refreshingly serious look at young women . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 2 / 4 / 0 / 6:  70% 7/10 [03:07<01:20, 26.77s/it]--------------------------------------------- Result 7 ---------------------------------------------\n",
            "\u001b[91mNegative (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "a sometimes tedious film . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 2 / 5 / 0 / 7:  80% 8/10 [03:23<00:50, 25.44s/it]--------------------------------------------- Result 8 ---------------------------------------------\n",
            "\u001b[91mNegative (99%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "or doing last year 's taxes with your ex-wife . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 2 / 6 / 0 / 8:  90% 9/10 [04:18<00:28, 28.72s/it]--------------------------------------------- Result 9 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "you do n't have to know about music to appreciate the film 's easygoing blend of comedy and romance . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 2 / 7 / 0 / 9: 100% 10/10 [04:49<00:00, 28.95s/it]--------------------------------------------- Result 10 ---------------------------------------------\n",
            "\u001b[91mNegative (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "in exactly 89 minutes , most of which passed as slowly as if i 'd been sitting naked on an igloo , formula 51 sank from quirky to jerky to utter turkey . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 2 / 8 / 0 / 10: 100% 10/10 [04:49<00:00, 28.95s/it]\n",
            "\n",
            "+-------------------------------+--------+\n",
            "| Attack Results                |        |\n",
            "+-------------------------------+--------+\n",
            "| Number of successful attacks: | 2      |\n",
            "| Number of failed attacks:     | 8      |\n",
            "| Number of skipped attacks:    | 0      |\n",
            "| Original accuracy:            | 100.0% |\n",
            "| Accuracy under attack:        | 80.0%  |\n",
            "| Attack success rate:          | 20.0%  |\n",
            "| Average perturbed word %:     | 16.78% |\n",
            "| Average num. words per input: | 13.4   |\n",
            "| Avg num queries:              | 8.8    |\n",
            "+-------------------------------+--------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!textattack attack --model bert-base-uncased-sst2 --recipe bert-attack --num-examples 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mpnRDEwNi2fS",
        "outputId": "d432dd13-55dc-49f4-e328-715a908a6fc8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: 28.7kB [00:00, 15.7MB/s]       \n",
            "Downloading: 28.7kB [00:00, 17.2MB/s]       \n",
            "Downloading and preparing dataset glue/sst2 (download: 7.09 MiB, generated: 4.81 MiB, post-processed: Unknown size, total: 11.90 MiB) to /root/.cache/huggingface/datasets/glue/sst2/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4...\n",
            "Downloading: 100% 7.44M/7.44M [00:00<00:00, 9.84MB/s]\n",
            "Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/sst2/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4. Subsequent calls will reuse this data.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mglue\u001b[0m, subset \u001b[94msst2\u001b[0m, split \u001b[94mvalidation\u001b[0m.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading pre-trained model from HuggingFace model repository: \u001b[94mtextattack/bert-base-uncased-SST-2\u001b[0m\n",
            "Downloading: 100% 477/477 [00:00<00:00, 263kB/s]\n",
            "Downloading: 100% 418M/418M [00:15<00:00, 27.7MB/s]\n",
            "Downloading: 100% 48.0/48.0 [00:00<00:00, 32.4kB/s]\n",
            "Downloading: 100% 226k/226k [00:00<00:00, 13.7MB/s]\n",
            "Downloading: 100% 112/112 [00:00<00:00, 78.4kB/s]\n",
            "Downloading: 100% 570/570 [00:00<00:00, 413kB/s]\n",
            "Downloading: 100% 420M/420M [00:08<00:00, 51.2MB/s]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Downloading: 100% 28.0/28.0 [00:00<00:00, 19.9kB/s]\n",
            "Downloading: 100% 226k/226k [00:00<00:00, 13.2MB/s]\n",
            "Downloading: 100% 455k/455k [00:00<00:00, 18.4MB/s]\n",
            "\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "Attack(\n",
            "  (search_method): GreedyWordSwapWIR(\n",
            "    (wir_method):  unk\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  WordSwapMaskedLM(\n",
            "    (method):  bert-attack\n",
            "    (masked_lm_name):  BertForMaskedLM\n",
            "    (max_length):  512\n",
            "    (max_candidates):  48\n",
            "    (min_confidence):  0.0005\n",
            "  )\n",
            "  (constraints): \n",
            "    (0): MaxWordsPerturbed(\n",
            "        (max_percent):  0.4\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): UniversalSentenceEncoder(\n",
            "        (metric):  cosine\n",
            "        (threshold):  0.2\n",
            "        (window_size):  inf\n",
            "        (skip_text_shorter_than_window):  False\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (2): RepeatModification\n",
            "    (3): StopwordModification\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n",
            "  0% 0/10 [00:00<?, ?it/s]2022-02-08 18:48:20.866491: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2022-02-08 18:48:22.215939: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 34133760 exceeds 10% of free system memory.\n",
            "2022-02-08 18:48:22.234804: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 34133760 exceeds 10% of free system memory.\n",
            "2022-02-08 18:48:22.254592: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 34133760 exceeds 10% of free system memory.\n",
            "2022-02-08 18:48:22.273194: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 34133760 exceeds 10% of free system memory.\n",
            "2022-02-08 18:48:22.291347: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 34133760 exceeds 10% of free system memory.\n",
            " 10% 1/10 [03:05<27:52, 185.78s/it]--------------------------------------------- Result 1 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (97%)\u001b[0m\n",
            "\n",
            "it 's a \u001b[92mcharming\u001b[0m and often \u001b[92maffecting\u001b[0m journey . \n",
            "\n",
            "it 's a \u001b[91mdangerous\u001b[0m and often \u001b[91munpleasant\u001b[0m journey . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 1 / 0 / 0 / 1:  20% 2/10 [04:26<17:46, 133.36s/it]--------------------------------------------- Result 2 ---------------------------------------------\n",
            "\u001b[91mNegative (99%)\u001b[0m --> \u001b[92mPositive (89%)\u001b[0m\n",
            "\n",
            "unflinchingly \u001b[91mbleak\u001b[0m and desperate \n",
            "\n",
            "unflinchingly \u001b[92mdark\u001b[0m and desperate \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 2 / 0 / 0 / 2:  30% 3/10 [08:22<19:33, 167.65s/it]--------------------------------------------- Result 3 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (55%)\u001b[0m\n",
            "\n",
            "allows us to hope that nolan is \u001b[92mpoised\u001b[0m to embark a major career as a commercial yet \u001b[92minventive\u001b[0m filmmaker . \n",
            "\n",
            "allows us to hope that nolan is \u001b[91maspirations\u001b[0m to embark a major career as a commercial yet \u001b[91minventoriented\u001b[0m filmmaker . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 3 / 0 / 0 / 3:  40% 4/10 [11:02<16:34, 165.68s/it]--------------------------------------------- Result 4 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (63%)\u001b[0m\n",
            "\n",
            "the acting , costumes , music , cinematography and sound are all \u001b[92mastounding\u001b[0m given the production 's austere locales . \n",
            "\n",
            "the acting , costumes , music , cinematography and sound are all \u001b[91matoufitting\u001b[0m given the production 's austere locales . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 4 / 0 / 0 / 4:  50% 5/10 [12:27<12:27, 149.41s/it]--------------------------------------------- Result 5 ---------------------------------------------\n",
            "\u001b[91mNegative (100%)\u001b[0m --> \u001b[92mPositive (99%)\u001b[0m\n",
            "\n",
            "it 's slow -- very , very \u001b[91mslow\u001b[0m . \n",
            "\n",
            "it 's slow -- very , very \u001b[92msweet\u001b[0m . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 5 / 0 / 0 / 5:  60% 6/10 [17:24<11:36, 174.08s/it]--------------------------------------------- Result 6 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (78%)\u001b[0m\n",
            "\n",
            "although laced with \u001b[92mhumor\u001b[0m and a few fanciful touches , the film is a \u001b[92mrefreshingly\u001b[0m \u001b[92mserious\u001b[0m \u001b[92mlook\u001b[0m at young women . \n",
            "\n",
            "although laced with \u001b[91mgag\u001b[0m and a few fanciful touches , the film is a \u001b[91mrefreshingrather\u001b[0m \u001b[91mnot\u001b[0m \u001b[91maimed\u001b[0m at young women . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 6 / 0 / 0 / 6:  70% 7/10 [18:55<08:06, 162.24s/it]--------------------------------------------- Result 7 ---------------------------------------------\n",
            "\u001b[91mNegative (100%)\u001b[0m --> \u001b[92mPositive (83%)\u001b[0m\n",
            "\n",
            "a sometimes \u001b[91mtedious\u001b[0m film . \n",
            "\n",
            "a sometimes \u001b[92mlongrequired\u001b[0m film . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 7 / 0 / 0 / 7:  80% 8/10 [21:44<05:26, 163.11s/it]--------------------------------------------- Result 8 ---------------------------------------------\n",
            "\u001b[91mNegative (99%)\u001b[0m --> \u001b[92mPositive (69%)\u001b[0m\n",
            "\n",
            "or doing last \u001b[91myear\u001b[0m 's \u001b[91mtaxes\u001b[0m with your ex-wife . \n",
            "\n",
            "or doing last \u001b[92msummer\u001b[0m 's \u001b[92mrocks\u001b[0m with your ex-wife . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 8 / 0 / 0 / 8:  90% 9/10 [26:23<02:55, 175.89s/it]--------------------------------------------- Result 9 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (83%)\u001b[0m\n",
            "\n",
            "you do n't have to know about music to \u001b[92mappreciate\u001b[0m the film 's \u001b[92measygoing\u001b[0m \u001b[92mblend\u001b[0m of comedy and romance . \n",
            "\n",
            "you do n't have to know about music to \u001b[91maverage\u001b[0m the film 's \u001b[91measyhonest\u001b[0m \u001b[91mfeature\u001b[0m of comedy and romance . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 9 / 0 / 0 / 9: 100% 10/10 [30:56<00:00, 185.69s/it]--------------------------------------------- Result 10 ---------------------------------------------\n",
            "\u001b[91mNegative (100%)\u001b[0m --> \u001b[92mPositive (75%)\u001b[0m\n",
            "\n",
            "in exactly 89 minutes , most of which passed as slowly as if i 'd been sitting naked on an igloo , \u001b[91mformula\u001b[0m 51 \u001b[91msank\u001b[0m from quirky to jerky to \u001b[91mutter\u001b[0m turkey . \n",
            "\n",
            "in exactly 89 minutes , most of which passed as slowly as if i 'd been sitting naked on an igloo , \u001b[92mthis\u001b[0m 51 \u001b[92mperformed\u001b[0m from quirky to jerky to \u001b[92mflawless\u001b[0m turkey . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 10 / 0 / 0 / 10: 100% 10/10 [30:56<00:00, 185.69s/it]\n",
            "\n",
            "+-------------------------------+--------+\n",
            "| Attack Results                |        |\n",
            "+-------------------------------+--------+\n",
            "| Number of successful attacks: | 10     |\n",
            "| Number of failed attacks:     | 0      |\n",
            "| Number of skipped attacks:    | 0      |\n",
            "| Original accuracy:            | 100.0% |\n",
            "| Accuracy under attack:        | 0.0%   |\n",
            "| Attack success rate:          | 100.0% |\n",
            "| Average perturbed word %:     | 17.75% |\n",
            "| Average num. words per input: | 13.4   |\n",
            "| Avg num queries:              | 100.3  |\n",
            "+-------------------------------+--------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!textattack attack --model bert-base-uncased-sst2 --recipe textfooler --num-examples 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rHkiGnRxEXtf",
        "outputId": "bdda91ef-65cc-4e29-f911-9fb2e9a31a6c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: 28.7kB [00:00, 14.8MB/s]       \n",
            "Downloading: 28.7kB [00:00, 15.9MB/s]       \n",
            "Downloading and preparing dataset glue/sst2 (download: 7.09 MiB, generated: 4.81 MiB, post-processed: Unknown size, total: 11.90 MiB) to /root/.cache/huggingface/datasets/glue/sst2/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4...\n",
            "Downloading: 100% 7.44M/7.44M [00:00<00:00, 10.5MB/s]\n",
            "Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/sst2/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4. Subsequent calls will reuse this data.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mglue\u001b[0m, subset \u001b[94msst2\u001b[0m, split \u001b[94mvalidation\u001b[0m.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading pre-trained model from HuggingFace model repository: \u001b[94mtextattack/bert-base-uncased-SST-2\u001b[0m\n",
            "Downloading: 100% 477/477 [00:00<00:00, 316kB/s]\n",
            "Downloading: 100% 418M/418M [00:15<00:00, 28.6MB/s]\n",
            "Downloading: 100% 48.0/48.0 [00:00<00:00, 34.7kB/s]\n",
            "Downloading: 100% 226k/226k [00:00<00:00, 2.89MB/s]\n",
            "Downloading: 100% 112/112 [00:00<00:00, 76.5kB/s]\n",
            "\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "Attack(\n",
            "  (search_method): GreedyWordSwapWIR(\n",
            "    (wir_method):  delete\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  WordSwapEmbedding(\n",
            "    (max_candidates):  50\n",
            "    (embedding):  WordEmbedding\n",
            "  )\n",
            "  (constraints): \n",
            "    (0): WordEmbeddingDistance(\n",
            "        (embedding):  WordEmbedding\n",
            "        (min_cos_sim):  0.5\n",
            "        (cased):  False\n",
            "        (include_unknown_words):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): PartOfSpeech(\n",
            "        (tagger_type):  nltk\n",
            "        (tagset):  universal\n",
            "        (allow_verb_noun_swap):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (2): UniversalSentenceEncoder(\n",
            "        (metric):  angular\n",
            "        (threshold):  0.840845057\n",
            "        (window_size):  15\n",
            "        (skip_text_shorter_than_window):  True\n",
            "        (compare_against_original):  False\n",
            "      )\n",
            "    (3): RepeatModification\n",
            "    (4): StopwordModification\n",
            "    (5): InputColumnModification(\n",
            "        (matching_column_labels):  ['premise', 'hypothesis']\n",
            "        (columns_to_ignore):  {'premise'}\n",
            "      )\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n",
            "  0% 0/10 [00:00<?, ?it/s]2022-02-08 04:45:38.966896: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2022-02-08 04:45:40.307533: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 34133760 exceeds 10% of free system memory.\n",
            "2022-02-08 04:45:40.325998: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 34133760 exceeds 10% of free system memory.\n",
            "2022-02-08 04:45:40.344125: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 34133760 exceeds 10% of free system memory.\n",
            "2022-02-08 04:45:40.361809: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 34133760 exceeds 10% of free system memory.\n",
            "2022-02-08 04:45:40.379798: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 34133760 exceeds 10% of free system memory.\n",
            " 10% 1/10 [02:20<21:01, 140.20s/it]--------------------------------------------- Result 1 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (100%)\u001b[0m\n",
            "\n",
            "it 's a \u001b[92mcharming\u001b[0m and often \u001b[92maffecting\u001b[0m journey . \n",
            "\n",
            "it 's a \u001b[91mcutie\u001b[0m and often \u001b[91mafflicts\u001b[0m journey . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 1 / 0 / 0 / 1:  20% 2/10 [03:21<13:24, 100.51s/it]--------------------------------------------- Result 2 ---------------------------------------------\n",
            "\u001b[91mNegative (99%)\u001b[0m --> \u001b[92mPositive (96%)\u001b[0m\n",
            "\n",
            "unflinchingly \u001b[91mbleak\u001b[0m and desperate \n",
            "\n",
            "unflinchingly \u001b[92meerie\u001b[0m and desperate \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 2 / 0 / 0 / 2:  30% 3/10 [08:31<19:54, 170.61s/it]--------------------------------------------- Result 3 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (53%)\u001b[0m\n",
            "\n",
            "allows \u001b[92mus\u001b[0m to hope that nolan is poised to \u001b[92membark\u001b[0m a \u001b[92mmajor\u001b[0m career as a commercial yet \u001b[92minventive\u001b[0m \u001b[92mfilmmaker\u001b[0m . \n",
            "\n",
            "allows \u001b[91mourselves\u001b[0m to hope that nolan is poised to \u001b[91membarked\u001b[0m a \u001b[91msevere\u001b[0m career as a commercial yet \u001b[91mnovelty\u001b[0m \u001b[91msuperintendent\u001b[0m . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 3 / 0 / 0 / 3:  40% 4/10 [09:18<13:58, 139.71s/it]--------------------------------------------- Result 4 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (93%)\u001b[0m\n",
            "\n",
            "the acting , costumes , music , cinematography and sound are all \u001b[92mastounding\u001b[0m given the production 's austere locales . \n",
            "\n",
            "the acting , costumes , music , cinematography and sound are all \u001b[91mbreathless\u001b[0m given the production 's austere locales . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 4 / 0 / 0 / 4:  50% 5/10 [12:52<12:52, 154.41s/it]--------------------------------------------- Result 5 ---------------------------------------------\n",
            "\u001b[91mNegative (100%)\u001b[0m --> \u001b[92mPositive (98%)\u001b[0m\n",
            "\n",
            "it 's slow -- \u001b[91mvery\u001b[0m , \u001b[91mvery\u001b[0m \u001b[91mslow\u001b[0m . \n",
            "\n",
            "it 's slow -- \u001b[92mpretty\u001b[0m , \u001b[92mperfectly\u001b[0m \u001b[92mlent\u001b[0m . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 5 / 0 / 0 / 5:  60% 6/10 [19:26<12:57, 194.44s/it]--------------------------------------------- Result 6 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (71%)\u001b[0m\n",
            "\n",
            "although laced with \u001b[92mhumor\u001b[0m and a few \u001b[92mfanciful\u001b[0m touches , the film is a \u001b[92mrefreshingly\u001b[0m serious \u001b[92mlook\u001b[0m at \u001b[92myoung\u001b[0m women . \n",
            "\n",
            "although laced with \u001b[91mdroll\u001b[0m and a few \u001b[91munreal\u001b[0m touches , the film is a \u001b[91mnonchalantly\u001b[0m serious \u001b[91mseem\u001b[0m at \u001b[91mchildish\u001b[0m women . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 6 / 0 / 0 / 6:  70% 7/10 [20:47<08:54, 178.27s/it]--------------------------------------------- Result 7 ---------------------------------------------\n",
            "\u001b[91mNegative (100%)\u001b[0m --> \u001b[92mPositive (87%)\u001b[0m\n",
            "\n",
            "a sometimes \u001b[91mtedious\u001b[0m film . \n",
            "\n",
            "a sometimes \u001b[92mtricky\u001b[0m film . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 7 / 0 / 0 / 7:  80% 8/10 [23:04<05:46, 173.02s/it]--------------------------------------------- Result 8 ---------------------------------------------\n",
            "\u001b[91mNegative (99%)\u001b[0m --> \u001b[92mPositive (99%)\u001b[0m\n",
            "\n",
            "or doing \u001b[91mlast\u001b[0m year 's \u001b[91mtaxes\u001b[0m with your ex-wife . \n",
            "\n",
            "or doing \u001b[92multimate\u001b[0m year 's \u001b[92mhonorarium\u001b[0m with your ex-wife . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 8 / 0 / 0 / 8:  90% 9/10 [27:20<03:02, 182.26s/it]--------------------------------------------- Result 9 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (77%)\u001b[0m\n",
            "\n",
            "you do n't \u001b[92mhave\u001b[0m to know about music to \u001b[92mappreciate\u001b[0m the film 's easygoing \u001b[92mblend\u001b[0m of comedy and romance . \n",
            "\n",
            "you do n't \u001b[91mgot\u001b[0m to know about music to \u001b[91mgreet\u001b[0m the film 's easygoing \u001b[91magitate\u001b[0m of comedy and romance . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 9 / 0 / 0 / 9: 100% 10/10 [31:34<00:00, 189.46s/it]--------------------------------------------- Result 10 ---------------------------------------------\n",
            "\u001b[91mNegative (100%)\u001b[0m --> \u001b[92mPositive (53%)\u001b[0m\n",
            "\n",
            "in exactly 89 minutes , most of which passed as slowly as if i 'd been sitting naked on an igloo , \u001b[91mformula\u001b[0m 51 \u001b[91msank\u001b[0m from quirky to jerky to \u001b[91mutter\u001b[0m \u001b[91mturkey\u001b[0m . \n",
            "\n",
            "in exactly 89 minutes , most of which passed as slowly as if i 'd been sitting naked on an igloo , \u001b[92mrecipes\u001b[0m 51 \u001b[92mflowed\u001b[0m from quirky to jerky to \u001b[92mfullest\u001b[0m \u001b[92manatolia\u001b[0m . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 10 / 0 / 0 / 10: 100% 10/10 [31:34<00:00, 189.46s/it]\n",
            "\n",
            "+-------------------------------+--------+\n",
            "| Attack Results                |        |\n",
            "+-------------------------------+--------+\n",
            "| Number of successful attacks: | 10     |\n",
            "| Number of failed attacks:     | 0      |\n",
            "| Number of skipped attacks:    | 0      |\n",
            "| Original accuracy:            | 100.0% |\n",
            "| Accuracy under attack:        | 0.0%   |\n",
            "| Attack success rate:          | 100.0% |\n",
            "| Average perturbed word %:     | 23.52% |\n",
            "| Average num. words per input: | 13.4   |\n",
            "| Avg num queries:              | 101.3  |\n",
            "+-------------------------------+--------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alzantot's genetic algorithm (GA) based attack is very slow (hours for one attack given the Colab computation resourse), so you may not want to re-run this cell below unless you have enough resource or waiting time. "
      ],
      "metadata": {
        "id": "YMs9waPB7SjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!textattack attack --model bert-base-uncased-sst2 --recipe alzantot --num-examples 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "v14ypmLPXGar",
        "outputId": "4a7beb0e-50c4-43db-9510-b0cb3fde8769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mglue\u001b[0m, subset \u001b[94msst2\u001b[0m, split \u001b[94mvalidation\u001b[0m.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading pre-trained model from HuggingFace model repository: \u001b[94mtextattack/bert-base-uncased-SST-2\u001b[0m\n",
            "\u001b[34;1mtextattack\u001b[0m: Downloading https://textattack.s3.amazonaws.com/constraints/semantics/language-models/alzantot-goog-lm.\n",
            "100% 3.87G/3.87G [02:27<00:00, 26.2MB/s]\n",
            "\u001b[34;1mtextattack\u001b[0m: Unzipping file /root/.cache/textattack/tmpuc_vnt15.zip to /root/.cache/textattack/constraints/semantics/language-models/alzantot-goog-lm.\n",
            "\u001b[34;1mtextattack\u001b[0m: Successfully saved constraints/semantics/language-models/alzantot-goog-lm to cache.\n",
            "2022-02-08 05:28:34.617206: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Recovering graph.\n",
            "INFO:tensorflow:Recovering Graph /root/.cache/textattack/constraints/semantics/language-models/alzantot-goog-lm/graph-2016-09-10-gpu.pbtxt\n",
            "Recovering Graph /root/.cache/textattack/constraints/semantics/language-models/alzantot-goog-lm/graph-2016-09-10-gpu.pbtxt\n",
            "Recovering checkpoint /root/.cache/textattack/constraints/semantics/language-models/alzantot-goog-lm/ckpt-*\n",
            "2022-02-08 05:28:37.629403: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 409600000 exceeds 10% of free system memory.\n",
            "2022-02-08 05:28:37.879950: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 409600000 exceeds 10% of free system memory.\n",
            "2022-02-08 05:28:38.955733: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 409600000 exceeds 10% of free system memory.\n",
            "2022-02-08 05:28:40.245641: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 409600000 exceeds 10% of free system memory.\n",
            "2022-02-08 05:28:44.059864: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 409600000 exceeds 10% of free system memory.\n",
            "\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "Attack(\n",
            "  (search_method): AlzantotGeneticAlgorithm(\n",
            "    (pop_size):  60\n",
            "    (max_iters):  20\n",
            "    (temp):  0.3\n",
            "    (give_up_if_no_improvement):  False\n",
            "    (post_crossover_check):  False\n",
            "    (max_crossover_retries):  20\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  WordSwapEmbedding(\n",
            "    (max_candidates):  8\n",
            "    (embedding):  WordEmbedding\n",
            "  )\n",
            "  (constraints): \n",
            "    (0): MaxWordsPerturbed(\n",
            "        (max_percent):  0.2\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): WordEmbeddingDistance(\n",
            "        (embedding):  WordEmbedding\n",
            "        (max_mse_dist):  0.5\n",
            "        (cased):  False\n",
            "        (include_unknown_words):  True\n",
            "        (compare_against_original):  False\n",
            "      )\n",
            "    (2): GoogleLanguageModel(\n",
            "        (top_n):  None\n",
            "        (top_n_per_index):  4\n",
            "        (compare_against_original):  False\n",
            "      )\n",
            "    (3): RepeatModification\n",
            "    (4): StopwordModification\n",
            "    (5): InputColumnModification(\n",
            "        (matching_column_labels):  ['premise', 'hypothesis']\n",
            "        (columns_to_ignore):  {'premise'}\n",
            "      )\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n",
            "  0% 0/10 [00:00<?, ?it/s]tcmalloc: large alloc 3276800000 bytes == 0x55fd71fe6000 @  0x7f23b0e75b6b 0x7f23b0e95379 0x7f226cbc4ea7 0x7f225ae170af 0x7f225aeb419b 0x7f225accac67 0x7f225accb4d0 0x7f225accb5d4 0x7f2261381e9a 0x7f225b05cb58 0x7f225afef564 0x7f2260ab7c61 0x7f2260ab4953 0x7f225b7152f5 0x7f23b0c486db 0x7f23afd7d71f\n",
            "tcmalloc: large alloc 3276800000 bytes == 0x55fd71fe6000 @  0x7f23b0e75b6b 0x7f23b0e95379 0x7f226cbc4ea7 0x7f225ae170af 0x7f225aeb419b 0x7f225accac67 0x7f225accb4d0 0x7f225accb5d4 0x7f2261381e9a 0x7f225b05cb58 0x7f225afef564 0x7f2260ab7c61 0x7f2260ab4953 0x7f225b7152f5 0x7f23b0c486db 0x7f23afd7d71f\n",
            "tcmalloc: large alloc 3276800000 bytes == 0x55fd81fe6000 @  0x7f23b0e75b6b 0x7f23b0e95379 0x7f226cbc4ea7 0x7f225ae170af 0x7f225aeb419b 0x7f225accac67 0x7f225accb4d0 0x7f225accb5d4 0x7f2261381e9a 0x7f225b05cb58 0x7f225afef564 0x7f2260ab7c61 0x7f2260ab4953 0x7f225b7152f5 0x7f23b0c486db 0x7f23afd7d71f\n",
            "tcmalloc: large alloc 3276800000 bytes == 0x55fd71fe6000 @  0x7f23b0e75b6b 0x7f23b0e95379 0x7f226cbc4ea7 0x7f225ae170af 0x7f225aeb419b 0x7f225accac67 0x7f225accb4d0 0x7f225accb5d4 0x7f2261381e9a 0x7f225b05cb58 0x7f225afef564 0x7f2260ab7c61 0x7f2260ab4953 0x7f225b7152f5 0x7f23b0c486db 0x7f23afd7d71f\n",
            "tcmalloc: large alloc 3276800000 bytes == 0x55fd71fe6000 @  0x7f23b0e75b6b 0x7f23b0e95379 0x7f226cbc4ea7 0x7f225ae170af 0x7f225aeb419b 0x7f225accac67 0x7f225accb4d0 0x7f225accb5d4 0x7f2261381e9a 0x7f225b05cb58 0x7f225afef564 0x7f2260ab7c61 0x7f2260ab4953 0x7f225b7152f5 0x7f23b0c486db 0x7f23afd7d71f\n",
            "tcmalloc: large alloc 3276800000 bytes == 0x55fd71fe6000 @  0x7f23b0e75b6b 0x7f23b0e95379 0x7f226cbc4ea7 0x7f225ae170af 0x7f225aeb419b 0x7f225accac67 0x7f225accb4d0 0x7f225accb5d4 0x7f2261381e9a 0x7f225b05cb58 0x7f225afef564 0x7f2260ab7c61 0x7f2260ab4953 0x7f225b7152f5 0x7f23b0c486db 0x7f23afd7d71f\n",
            "tcmalloc: large alloc 3276800000 bytes == 0x55fd71fe6000 @  0x7f23b0e75b6b 0x7f23b0e95379 0x7f226cbc4ea7 0x7f225ae170af 0x7f225aeb419b 0x7f225accac67 0x7f225accb4d0 0x7f225accb5d4 0x7f2261381e9a 0x7f225b05cb58 0x7f225afef564 0x7f2260ab7c61 0x7f2260ab4953 0x7f225b7152f5 0x7f23b0c486db 0x7f23afd7d71f\n",
            "tcmalloc: large alloc 3276800000 bytes == 0x55fd71fe6000 @  0x7f23b0e75b6b 0x7f23b0e95379 0x7f226cbc4ea7 0x7f225ae170af 0x7f225aeb419b 0x7f225accac67 0x7f225accb4d0 0x7f225accb5d4 0x7f2261381e9a 0x7f225b05cb58 0x7f225afef564 0x7f2260ab7c61 0x7f2260ab4953 0x7f225b7152f5 0x7f23b0c486db 0x7f23afd7d71f\n",
            "tcmalloc: large alloc 3276800000 bytes == 0x55fd71fe6000 @  0x7f23b0e75b6b 0x7f23b0e95379 0x7f226cbc4ea7 0x7f225ae170af 0x7f225aeb419b 0x7f225accac67 0x7f225accb4d0 0x7f225accb5d4 0x7f2261381e9a 0x7f225b05cb58 0x7f225afef564 0x7f2260ab7c61 0x7f2260ab4953 0x7f225b7152f5 0x7f23b0c486db 0x7f23afd7d71f\n",
            "tcmalloc: large alloc 3276800000 bytes == 0x55fd71fe6000 @  0x7f23b0e75b6b 0x7f23b0e95379 0x7f226cbc4ea7 0x7f225ae170af 0x7f225aeb419b 0x7f225accac67 0x7f225accb4d0 0x7f225accb5d4 0x7f2261381e9a 0x7f225b05cb58 0x7f225afef564 0x7f2260ab7c61 0x7f2260ab4953 0x7f225b7152f5 0x7f23b0c486db 0x7f23afd7d71f\n",
            " 10% 1/10 [32:56<4:56:30, 1976.75s/it]--------------------------------------------- Result 1 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "it 's a charming and often affecting journey . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:  20% 2/10 [33:23<2:13:34, 1001.85s/it]--------------------------------------------- Result 2 ---------------------------------------------\n",
            "\u001b[91mNegative (99%)\u001b[0m --> \u001b[92mPositive (90%)\u001b[0m\n",
            "\n",
            "unflinchingly \u001b[91mbleak\u001b[0m and desperate \n",
            "\n",
            "unflinchingly \u001b[92mdusky\u001b[0m and desperate \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 1 / 1 / 0 / 2:  30% 3/10 [1:00:57<2:22:13, 1219.06s/it]--------------------------------------------- Result 3 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (98%)\u001b[0m\n",
            "\n",
            "allows us to \u001b[92mhope\u001b[0m that \u001b[92mnolan\u001b[0m is \u001b[92mpoised\u001b[0m to embark a major career as a commercial \u001b[92myet\u001b[0m inventive filmmaker . \n",
            "\n",
            "allows us to \u001b[91mhopes\u001b[0m that \u001b[91meastwood\u001b[0m is \u001b[91mprepped\u001b[0m to embark a major career as a commercial \u001b[91mhowever\u001b[0m inventive filmmaker . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 2 / 1 / 0 / 3:  40% 4/10 [1:25:16<2:07:54, 1279.09s/it]--------------------------------------------- Result 4 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (67%)\u001b[0m\n",
            "\n",
            "the acting , costumes , \u001b[92mmusic\u001b[0m , \u001b[92mcinematography\u001b[0m and \u001b[92msound\u001b[0m are all astounding \u001b[92mgiven\u001b[0m the production 's austere locales . \n",
            "\n",
            "the acting , costumes , \u001b[91mmusician\u001b[0m , \u001b[91mcinematographer\u001b[0m and \u001b[91maudio\u001b[0m are all astounding \u001b[91mgave\u001b[0m the production 's austere locales . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 3 / 1 / 0 / 4:  50% 5/10 [1:29:49<1:29:49, 1077.81s/it]--------------------------------------------- Result 5 ---------------------------------------------\n",
            "\u001b[91mNegative (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "it 's slow -- very , very slow . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 3 / 2 / 0 / 5:  60% 6/10 [2:31:05<1:40:43, 1510.88s/it]--------------------------------------------- Result 6 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91mNegative (55%)\u001b[0m\n",
            "\n",
            "\u001b[92malthough\u001b[0m laced with \u001b[92mhumor\u001b[0m and a few \u001b[92mfanciful\u001b[0m touches , the \u001b[92mfilm\u001b[0m is a \u001b[92mrefreshingly\u001b[0m \u001b[92mserious\u001b[0m look at \u001b[92myoung\u001b[0m women . \n",
            "\n",
            "\u001b[91mwhilst\u001b[0m laced with \u001b[91mmood\u001b[0m and a few \u001b[91mimaginative\u001b[0m touches , the \u001b[91mfilmmaking\u001b[0m is a \u001b[91mneatly\u001b[0m \u001b[91mgrave\u001b[0m look at \u001b[91myouths\u001b[0m women . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 4 / 2 / 0 / 6:  70% 7/10 [2:31:43<1:05:01, 1300.50s/it]--------------------------------------------- Result 7 ---------------------------------------------\n",
            "\u001b[91mNegative (100%)\u001b[0m --> \u001b[92mPositive (100%)\u001b[0m\n",
            "\n",
            "a \u001b[91msometimes\u001b[0m tedious film . \n",
            "\n",
            "a \u001b[92mseldom\u001b[0m tedious film . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 5 / 2 / 0 / 7:  80% 8/10 [2:35:57<38:59, 1169.67s/it]  --------------------------------------------- Result 8 ---------------------------------------------\n",
            "\u001b[91mNegative (99%)\u001b[0m --> \u001b[92mPositive (85%)\u001b[0m\n",
            "\n",
            "or doing last \u001b[91myear\u001b[0m 's \u001b[91mtaxes\u001b[0m with your ex-wife . \n",
            "\n",
            "or doing last \u001b[92mleto\u001b[0m 's \u001b[92mroyalty\u001b[0m with your ex-wife . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 6 / 2 / 0 / 8:  90% 9/10 [4:03:31<27:03, 1623.45s/it]--------------------------------------------- Result 9 ---------------------------------------------\n",
            "\u001b[92mPositive (100%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
            "\n",
            "you do n't have to know about music to appreciate the film 's easygoing blend of comedy and romance . \n",
            "\n",
            "\n",
            "[Succeeded / Failed / Skipped / Total] 6 / 3 / 0 / 9:  90% 9/10 [4:03:31<27:03, 1623.45s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RooIefDqxV4t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}